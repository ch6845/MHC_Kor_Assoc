{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\njupyter nbconvert 5_association.ipynb --to script\\npython 5_association.py albumin 2 0\\n\\nfor i in {00..101};do python 5_association.py $i 2 1;done\\n\\n\\nfor i in {00..10};do python 5_association.py $i 2 0;done\\nfor i in {11..20};do python 5_association.py $i 2 0;done\\nfor i in {21..30};do python 5_association.py $i 2 0;done\\nfor i in {31..40};do python 5_association.py $i 2 0;done\\nfor i in {41..50};do python 5_association.py $i 2 0;done\\nfor i in {51..60};do python 5_association.py $i 2 0;done\\nfor i in {61..70};do python 5_association.py $i 2 0;done\\nfor i in {71..80};do python 5_association.py $i 2 0;done\\nfor i in {91..90};do python 5_association.py $i 2 0;done\\nfor i in {91..101};do python 5_association.py $i 2 0;done\\nfor i in {51..60};do python 5_association.py $i 2 0;done\\nfor i in {51..60};do python 5_association.py $i 2 0;done\\nfor i in {51..60};do python 5_association.py $i 2 0;done\\n\\nfor i in {00..101};do python 5_association.py $i 1 0,2;done\\nfor i in {00..101};do python 5_association.py $i 1 1;done\\n\\nfor i in {00..20};do python 5_association.py $i 1 1;done\\nfor i in {21..40};do python 5_association.py $i 1 1;done\\nfor i in {41..60};do python 5_association.py $i 1 1;done\\nfor i in {61..80};do python 5_association.py $i 1 1;done\\nfor i in {81..101};do python 5_association.py $i 1 1;done\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "import re\n",
    "import pathlib\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyplink import PyPlink\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from basic_tools import *\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "jupyter nbconvert 5_association.ipynb --to script\n",
    "python 5_association.py albumin 2 0\n",
    "\n",
    "for i in {00..101};do python 5_association.py $i 2 1;done\n",
    "\n",
    "\n",
    "for i in {00..10};do python 5_association.py $i 2 0;done\n",
    "for i in {11..20};do python 5_association.py $i 2 0;done\n",
    "for i in {21..30};do python 5_association.py $i 2 0;done\n",
    "for i in {31..40};do python 5_association.py $i 2 0;done\n",
    "for i in {41..50};do python 5_association.py $i 2 0;done\n",
    "for i in {51..60};do python 5_association.py $i 2 0;done\n",
    "for i in {61..70};do python 5_association.py $i 2 0;done\n",
    "for i in {71..80};do python 5_association.py $i 2 0;done\n",
    "for i in {91..90};do python 5_association.py $i 2 0;done\n",
    "for i in {91..101};do python 5_association.py $i 2 0;done\n",
    "for i in {51..60};do python 5_association.py $i 2 0;done\n",
    "for i in {51..60};do python 5_association.py $i 2 0;done\n",
    "for i in {51..60};do python 5_association.py $i 2 0;done\n",
    "\n",
    "for i in {00..101};do python 5_association.py $i 1 0,2;done\n",
    "for i in {00..101};do python 5_association.py $i 1 1;done\n",
    "\n",
    "for i in {00..20};do python 5_association.py $i 1 1;done\n",
    "for i in {21..40};do python 5_association.py $i 1 1;done\n",
    "for i in {41..60};do python 5_association.py $i 1 1;done\n",
    "for i in {61..80};do python 5_association.py $i 1 1;done\n",
    "for i in {81..101};do python 5_association.py $i 1 1;done\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plink_KCHIP_HLA_AA_SNP_1000G=PyPlink(plink_KCHIP_HLA_AA_SNP_1000G_path)\n",
    "plink_KCHIP_HLA_AA_SNP_1000G_fam=plink_KCHIP_HLA_AA_SNP_1000G.get_fam().astype({'fid':str,'iid':str}).rename(columns={'fid':'FID','iid':'IID'})\n",
    "plink_KCHIP_HLA_AA_SNP_1000G_bim=plink_KCHIP_HLA_AA_SNP_1000G.get_bim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes=pd.read_csv(pheno_all_file_path,sep='\\t')\n",
    "phenotypes=phenotypes.set_index('ID').loc[plink_KCHIP_HLA_AA_SNP_1000G_fam['IID']]\n",
    "\n",
    "binary_continuous_traits=sorted(phenotypes.columns[~phenotypes.columns.str.contains('x_ray')])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HLA_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a1_freq_case_control(row):\n",
    "    dosage=plink_KCHIP_HLA_AA_SNP_1000G.get_geno_marker(row['marker_name']).astype(float)\n",
    "    dosage[dosage==-1]=np.nan\n",
    "    if plink_KCHIP_HLA_AA_SNP_1000G_bim.loc[row['marker_name']]['a1']==row['A1'] and plink_KCHIP_HLA_AA_SNP_1000G_bim.loc[row['marker_name']]['a2']==row['A2']:\n",
    "        pass\n",
    "    elif plink_KCHIP_HLA_AA_SNP_1000G_bim.loc[row['marker_name']]['a1']==row['A2'] and plink_KCHIP_HLA_AA_SNP_1000G_bim.loc[row['marker_name']]['a2']==row['A1']:\n",
    "        dosage=2-dosage\n",
    "        \n",
    "    dosage_control=dosage[pheno['pheno']==1]\n",
    "    dosage_case=dosage[pheno['pheno']==2]\n",
    "    \n",
    "    a1_freq_case=(2*(dosage_case==2).sum()+1*(dosage_case==1).sum())/(2*dosage_case.shape[0])\n",
    "    a1_freq_control=(2*(dosage_control==2).sum()+1*(dosage_control==1).sum())/(2*dosage_control.shape[0])\n",
    "    \n",
    "    return a1_freq_case,a1_freq_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_pos(name):\n",
    "    if name[:3]=='AA_':\n",
    "        return int(name.split('_')[3])\n",
    "    elif name[:4]=='HLA_':\n",
    "        return plink_KCHIP_HLA_AA_SNP_1000G_bim.loc[plink_KCHIP_HLA_AA_SNP_1000G_bim.index.str.contains('HLA_'+name.split('*')[0].split('_')[1]+'*')].iloc[0]['pos']\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meets end 9\n",
      "meets end 2\n",
      "meets end 3\n",
      "meets end 3\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 5\n",
      "meets end 3\n",
      "meets end 3\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 4\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 3\n",
      "meets end 4\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 3\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 4\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 7\n",
      "meets end 3\n",
      "meets end 3\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 3\n",
      "meets end 2\n",
      "meets end 3\n",
      "meets end 5\n",
      "meets end 2\n",
      "meets end 7\n",
      "meets end 6\n",
      "meets end 3\n",
      "meets end 5\n",
      "meets end 3\n",
      "meets end 5\n",
      "meets end 3\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 6\n",
      "meets end 4\n",
      "meets end 3\n",
      "meets end 2\n",
      "meets end 3\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 7\n",
      "meets end 2\n",
      "meets end 3\n",
      "meets end 2\n",
      "meets end 3\n",
      "meets end 2\n",
      "meets end 5\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 3\n",
      "meets end 2\n",
      "meets end 4\n",
      "meets end 2\n",
      "meets end 3\n",
      "meets end 2\n",
      "meets end 4\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 2\n",
      "meets end 5\n",
      "meets end 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assoc_result_list=[]\n",
    "for phenotype_name in binary_continuous_traits:\n",
    "    if phenotype_name=='sex' or phenotype_name=='age':\n",
    "        continue\n",
    "    data_out_assoc_phenotype_path=data_out_assoc_path+phenotype_name+'/'\n",
    "      \n",
    "\n",
    "    for step_idx_sub in range(1,100):\n",
    "        #print(step_idx_sub)\n",
    "        if os.path.exists(data_out_assoc_phenotype_path+'step_{:02d}.cond.stop'.format(step_idx_sub)):\n",
    "            print('meets end',step_idx_sub)\n",
    "            break\n",
    "        result_merge=pd.read_csv(data_out_assoc_phenotype_path+'step_{:02d}.merge.result.tsv'.format(step_idx_sub),sep='\\t')\n",
    "        assoc_result_list.append(result_merge.sort_values('P').iloc[0])\n",
    "        \"\"\"\n",
    "        GAT_result=pd.read_csv(data_out_assoc_phenotype_path+'step_{:02d}.GAT.result.tsv'.format(step_idx_sub),sep='\\t')\n",
    "        GAT_result['POS']=GAT_result['marker_name'].map(name_to_pos)\n",
    "\n",
    "        plink_result=pd.read_csv(data_out_assoc_phenotype_path+'step_{:02d}.plink.PHENO2.glm.{}'.format(step_idx_sub,'logistic' if phenotype_type=='binary' else 'linear'),sep='\\t')\n",
    "        plink_result_munge=plink_result[plink_result['TEST']=='ADD'].drop(columns='#CHROM').rename(columns={'TEST':'term','ID':'marker_name','BETA':'coef','SE':'std','T_STAT':'Z','Z_STAT':'Z','OBS_CT':'nobs'})\n",
    "        plink_result_munge['A2']=plink_result_munge.apply(lambda x: x['ALT'] if x['A1']==x['REF'] else x['REF'],axis=1)\n",
    "        if phenotype_type=='binary':\n",
    "            assert set(pheno['pheno'].unique())=={-9,1,2}\n",
    "            a1_freq_case_control=plink_result_munge.apply(get_a1_freq,axis=1)\n",
    "            plink_result_munge['A1_freq_case']=[i[0] for i in a1_freq_case_control]\n",
    "            plink_result_munge['A1_freq_control']=[i[1] for i in a1_freq_case_control]\n",
    "        else:\n",
    "            plink_result_munge['A1_freq_case'],plink_result_munge['A1_freq_control']=np.nan,np.nan\n",
    "        plink_result_munge=plink_result_munge.drop(columns=['REF','ALT'])\n",
    "        plink_result_munge['note']='unphased bialleic'\n",
    "\n",
    "        result_merge=pd.concat([GAT_result,plink_result_munge],sort=True)\n",
    "        result_merge['phenotype_name']=phenotype_name\n",
    "        if phenotype_type=='binary':\n",
    "            result_merge['samples(case/control)']='{}/{}'.format((pheno['pheno']==2).sum(),(pheno['pheno']==1).sum())\n",
    "        else:\n",
    "            result_merge['samples(case/control)']='{}'.format((pheno['pheno']!=-9).sum())\n",
    "\n",
    "        result_merge['step']=step_idx_sub\n",
    "        with open(data_out_assoc_phenotype_path+'step_{:02d}.cond'.format(step_idx_sub)) as f:\n",
    "            result_merge['condition']=','.join(f.read().split())        \n",
    "        result_merge=result_merge[['phenotype_name','samples(case/control)','step','condition','marker_name','note','term','POS','A1','A2','A1_freq_case','A1_freq_control','multi_allele','nobs','Z','coef','std','chisq','df','P']]\n",
    "        result_merge.sort_values('POS').to_csv(data_out_assoc_phenotype_path+'step_{:02d}.merge.result.tsv'.format(step_idx_sub),sep='\\t')\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(assoc_result_list,axis=1).transpose().to_csv('result.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_merge_sorted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-43e5f5075ea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0massoc_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_merge_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result_merge_sorted' is not defined"
     ]
    }
   ],
   "source": [
    "assoc_result_list.append(result_merge_sorted.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
